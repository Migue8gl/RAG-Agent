- #responsibleai | #bestpractices | #google | #ethics
- [[notas whisper]]

# Contexto
- Este documento explora las lecciones aprendidas por Google al operacionalizar sus principios de *AI* y cómo estas han llevado al desarrollo de un conjunto de mejores prácticas.
- Se enfatiza la importancia de la diversidad, la inclusión y la educación en la adopción de *AI* responsable.

# Lecciones aprendidas
- La formación de un comité de revisión diverso en identidad cultural, experiencia y senioridad es fundamental para la interpretación de los principios de *AI*. Esto asegura que el comité represente mejor a la base de usuarios actual o potencial.
## Diversidad, equidad e inclusión
- Incluir consideraciones de **DEI** en los equipos multidisciplinarios fomenta decisiones más informadas y soluciones más viables.

# Adopción de principios de AI
- La adopción de principios de *AI* requiere apoyo tanto de arriba hacia abajo como de abajo hacia arriba. Un mandato de liderazgo es necesario, pero no suficiente; la participación de los equipos es crucial para normalizar la cultura de *AI* responsable.
## Educación y formación
- Es esencial educar a los equipos técnicos y de producto sobre ética tecnológica y fomentar que los interesados no técnicos comprendan los impactos tecnológicos, comerciales y sociales de la *AI*.

# Transparencia y documentación
- La transparencia en el proceso de gobernanza de *AI* responsable es vital para construir confianza. Aunque la confidencialidad es necesaria en detalles individuales, la transparencia en el proceso ayuda a establecer credibilidad.
## Registro de decisiones
- Desarrollar un sistema para rastrear planes de alineación, incluyendo problemas y mitigaciones, es crucial para informar el trabajo futuro y las revisiones.

# Enfoque humilde y balanceado
- Mantener un enfoque humilde es importante, ya que la *AI* está en constante cambio. Es necesario equilibrar la consistencia en las interpretaciones con la apertura a nueva investigación.
## Seguridad psicológica
- Invertir en **seguridad psicológica** permite a los equipos explorar preguntas hipotéticas y áreas de uso indebido, lo que es esencial para identificar problemas potenciales.

# Eficiencia y ética
- La eficiencia no debe ser el objetivo principal en el proceso de principios de *AI*. Es necesario equilibrar los objetivos de desarrollo del producto con el tiempo requerido para una revisión exhaustiva.
## Suposición de atención
- Asumir que cada aplicación de *AI* necesita atención ayuda a identificar problemas éticos que pueden no ser evidentes, promoviendo una exploración exhaustiva de escenarios posibles.

Estas son algunas de las mejores prácticas que Google ha aprendido al operacionalizar sus principios de *AI*, y se espera que evolucionen con el tiempo.